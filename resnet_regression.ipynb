{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "resnet_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abbyambita/Backpropagation-Algorithm-Implementation/blob/master/resnet_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpzdODsZsaQx"
      },
      "source": [
        "## Google Authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYhtmejKsTRe",
        "outputId": "c23eb3b1-8f61-4fcb-a357-3317a9993b04"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyTk5DRusYf3",
        "outputId": "cda684d5-ddc3-41b4-ab66-9aa8d73b06e3"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "os.chdir(\"/content/gdrive/My Drive\")\r\n",
        "\r\n",
        "!ls  '/content/gdrive/My Drive/CS 300/Code/'\r\n",
        "\r\n",
        "%cd \"/content/gdrive/My Drive/CS 300/Code\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acgan_output_images\t renamed_labeled_dataset_12x12\n",
            "build_datasets.ipynb\t resnet_regression_12x12.ipynb\n",
            "dataset\t\t\t resnet_regression.ipynb\n",
            "image2mass\t\t transfer_learning_models_1212.ipynb\n",
            "labeled_dataset\t\t transfer_learning_models.ipynb\n",
            "Mass_Flow_Estimation\t transfer_learning_with_acgan_kaggle.ipynb\n",
            "model_backup\t\t trial_acgan_kaggle.ipynb\n",
            "model_result\t\t tsne_acgan_git.ipynb\n",
            "output_result\t\t Untitled0.ipynb\n",
            "plots\t\t\t ViT_H_14.ipynb\n",
            "renamed_labeled_dataset  ViT-pytorch\n",
            "/content/gdrive/.shortcut-targets-by-id/15tH5Hjusd1sYm2KqoKTIP43Ew95os4Xp/CS 300/Code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxrKp-yZsfOd"
      },
      "source": [
        "## Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyhzIQ4DsmxV"
      },
      "source": [
        "import argparse\r\n",
        "import torch\r\n",
        "import os\r\n",
        "from torchvision import transforms, utils, datasets, models\r\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Dataset\r\n",
        "from torch import nn\r\n",
        "from torch import optim\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import torch.nn.functional as F\r\n",
        "from collections import OrderedDict\r\n",
        "import time\r\n",
        "from PIL import Image\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "import copy\r\n",
        "import shutil\r\n",
        "import sys\r\n",
        "from google.colab import files\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s_FHdB4stPu"
      },
      "source": [
        "dir = r'labeled_dataset'\r\n",
        "\r\n",
        "def remove_stray_files(image_path):\r\n",
        "  \"\"\"\r\n",
        "  Remove the labeled-dataset directory everytime the script is run\r\n",
        "  to avoid the chance of stray images being present in the directory\r\n",
        "  :param image_path - a directory specifying the source of images\r\n",
        "  return - None\r\n",
        "  \"\"\"\r\n",
        "  try:\r\n",
        "    shutil.rmtree(image_path)\r\n",
        "  except OSError:\r\n",
        "    print(\"directory  doesn't exist\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keRqPeX9szt2"
      },
      "source": [
        "def parse_gauze_info(path, file):\r\n",
        "  \"\"\"\r\n",
        "  Parse the Gauze info file that\r\n",
        "  contains the numerical data for\r\n",
        "  each gauze\r\n",
        "  :param path - a directory to the file\r\n",
        "  :param file - a text file delimited by space\r\n",
        "  return - a DataFrame\r\n",
        "  \"\"\"\r\n",
        "  gauzes = pd.read_csv(os.path.join(path, file))\r\n",
        "  gauzes['amount(ml)'] = gauzes['amount(ml)'].astype('int')\r\n",
        "\r\n",
        "  \r\n",
        "  return gauzes[['filename','amount(ml)','gauze_id']]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APNdcFho3FZY"
      },
      "source": [
        "#rename the images in labeled_dataset by the id \r\n",
        "\r\n",
        "# gauzes = parse_gauze_info(r'labeled_dataset', 'labels_4x4.csv')\r\n",
        "\r\n",
        "# for id in gauzes['filename']:\r\n",
        "#   gauze_id = gauzes[gauzes['filename']==id]['gauze_id'].values[0]\r\n",
        "#   os.rename('labeled_dataset/'+id, 'renamed_labeled_dataset/'+ str(gauze_id) + \".png\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Kn_rgAt29g"
      },
      "source": [
        "from sklearn.model_selection import KFold\r\n",
        "def split_into_train_test_valid(image_path, split_ratio=0.1):\r\n",
        "  gauze_ids = set()\r\n",
        "  for file in os.listdir(image_path):\r\n",
        "    if file.endswith('.png'):\r\n",
        "      gauze_ids.add(int(file.split('.')[0]))\r\n",
        "\r\n",
        "  # gauze_ids = list(gauze_ids)  \r\n",
        "  # np.random.shuffle(gauze_ids)    \r\n",
        "  # num_gauzes = len(gauze_ids)\r\n",
        "  # split_num = int(num_gauzes * split_ratio)\r\n",
        "  # test_ids = gauze_ids[:split_num]\r\n",
        "  # train_ids = gauze_ids[split_num:]\r\n",
        "  # num_gauzes = len(train_ids)\r\n",
        "  # split_num = int(num_gauzes * split_ratio)\r\n",
        "  # valid_ids = train_ids[:split_num]\r\n",
        "  # train_ids = train_ids[split_num:]\r\n",
        "\r\n",
        "  kf = KFold(n_splits=10)\r\n",
        "  gauze_ids = np.array(list(gauze_ids))\r\n",
        "  num_gauzes = len(gauze_ids)\r\n",
        "\r\n",
        "  train_ids = []\r\n",
        "  test_ids = []\r\n",
        "  valid_ids = []\r\n",
        "\r\n",
        "  split_num = int(num_gauzes * split_ratio)\r\n",
        "\r\n",
        "  for i, (train_index, test_index) in enumerate(kf.split(gauze_ids)):\r\n",
        "    train_id = gauze_ids[train_index]\r\n",
        "    test_id = gauze_ids[test_index]\r\n",
        "\r\n",
        "    split_num = int(num_gauzes * split_ratio)\r\n",
        "    val_id = train_id[:split_num]\r\n",
        "    train_id = train_id[split_num:]\r\n",
        "\r\n",
        "    test_ids.append(test_id)\r\n",
        "    valid_ids.append(val_id)\r\n",
        "    train_ids.append(train_id)\r\n",
        "\r\n",
        "\r\n",
        "  return train_ids, test_ids, valid_ids"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRI5aSiOuF8t"
      },
      "source": [
        "def make_dirs_copy_images(image_path, split, *gauze_ids):\r\n",
        "  \"\"\"\r\n",
        "  Make train, test and validation directories\r\n",
        "  and copy the files from `image_path` to their\r\n",
        "  respective directories using `gauze_ids`\r\n",
        "  :param image_path - a directory specifying the source of images\r\n",
        "  :param gauze_ids - a list of gauze ids for train, test and validation images\r\n",
        "  return - None\r\n",
        "  \"\"\"\r\n",
        "  try:\r\n",
        "    os.makedirs(os.path.join(image_path+\"/\"+split, 'train'), exist_ok=True)\r\n",
        "  except FileExistsError:\r\n",
        "    pass\r\n",
        "  \r\n",
        "  try:\r\n",
        "    os.makedirs(os.path.join(image_path+\"/\"+split, 'test'), exist_ok=True)\r\n",
        "  except FileExistsError:\r\n",
        "    pass\r\n",
        "  \r\n",
        "  try:\r\n",
        "    os.makedirs(os.path.join(image_path+\"/\"+split, 'valid'), exist_ok=True)\r\n",
        "  except FileExistsError:\r\n",
        "    pass\r\n",
        "  \r\n",
        "  train_ids, test_ids, valid_ids = gauze_ids\r\n",
        "  for file in os.listdir(image_path):\r\n",
        "    gauze_id = file.split('.')[0]\r\n",
        "    if file.endswith('.png'):\r\n",
        "      if int(gauze_id) in train_ids:\r\n",
        "        shutil.copy(os.path.join(image_path, file), \r\n",
        "                   os.path.join(image_path+\"/\"+split, 'train', file))\r\n",
        "      elif int(gauze_id) in test_ids:\r\n",
        "        shutil.copy(os.path.join(image_path, file), \r\n",
        "                   os.path.join(image_path+\"/\"+split, 'test', file))\r\n",
        "      else:\r\n",
        "        shutil.copy(os.path.join(image_path, file), \r\n",
        "                   os.path.join(image_path+\"/\"+split, 'valid', file))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ0A_rDquPUo"
      },
      "source": [
        "def load_images(gauze_ids, image_path, folder):\r\n",
        "  \"\"\"\r\n",
        "  Load the images for a given gauze in sorted\r\n",
        "  order so it is uniform for all gauzes\r\n",
        "  :param gauze_ids - a list of gauze ids\r\n",
        "  :param image_path - a path specifying the directory to the source images\r\n",
        "  :param folder - a folder, whether train, test or valid\r\n",
        "  return - a sorted list of gauze image paths\r\n",
        "  \"\"\"\r\n",
        "  gauzes_paths = []\r\n",
        "  for idx in gauze_ids:\r\n",
        "    # bedroom, bathroom, frontal view and kitchen images\r\n",
        "    source_image_path = os.path.join(image_path, folder, \"{}.png\".format(idx))\r\n",
        "    files = list(glob.glob(source_image_path))\r\n",
        "    gauzes_paths.append(sorted(files))\r\n",
        "\r\n",
        "  #print(gauzes_paths)\r\n",
        "  return gauzes_paths"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw8jFiUgKQeE"
      },
      "source": [
        "def tile_images(files_list, size=128):\r\n",
        "  print(files_list)\r\n",
        "\r\n",
        "  gauzes = []\r\n",
        "  #tile_size = (size, size)\r\n",
        "  for gauze in files_list:\r\n",
        "    \r\n",
        "    image = Image.open(gauze)\r\n",
        "    image = image.convert('RGB')\r\n",
        "    # img_list = []\r\n",
        "    # tiled_image = np.zeros((tile_size[0] * 2, tile_size[1] * 2, 3), dtype='uint8')\r\n",
        "    # for i, location in enumerate(house):\r\n",
        "    #   image = Image.open(location)\r\n",
        "    #   image = image.convert('RGB')\r\n",
        "    #   img_list.append(image.resize(tile_size))\r\n",
        "    # tiled_image = np.vstack([np.hstack([img_list[0], img_list[1]]), \r\n",
        "    #                          np.hstack([img_list[2], img_list[3]])])\r\n",
        "    # convert to PIL from numpy\r\n",
        "    gauzes.append(Image.fromarray(image))\r\n",
        "  return gauzes"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdJwJeJLveSc"
      },
      "source": [
        "class GauzeDataset(Dataset):\r\n",
        "  \"\"\"\r\n",
        "  Custom dataset class for gauzes dataset\r\n",
        "  Load all gauze images\r\n",
        "  Index through each tiled gauze and its amount\r\n",
        "  \"\"\"\r\n",
        "  \r\n",
        "  def __init__(self, df, gauze_ids, path, folder, size, transform=None):\r\n",
        "    self.path = path\r\n",
        "    self.files = load_images(gauze_ids, path, folder)\r\n",
        "    self.transform = transform\r\n",
        "    self.df = df\r\n",
        "    self.gauze_ids = gauze_ids\r\n",
        "    #self.size = size\r\n",
        "    # self.gauzes = tile_images(self.files, self.size)\r\n",
        "    self.scale_factor = 1e6\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.files)\r\n",
        "  \r\n",
        "  def __getitem__(self, idx):\r\n",
        "    if torch.is_tensor(idx):\r\n",
        "            idx = idx.tolist()\r\n",
        "\r\n",
        "    # given that the response variable is the gauze price\r\n",
        "    # we will pass that along with the respective gauze\r\n",
        "    # Log transform the amount\r\n",
        "    # if self.transform:\r\n",
        "    #   #return self.transform(self.gauzes[idx]), torch.tensor(np.log(self.df.loc[self.gauze_ids[idx]-1, 'amount']))\r\n",
        "    #   return self.transform(self.files[idx]), torch.tensor(np.log(self.df.loc[self.gauze_ids[idx]-1, 'amount(ml)']))\r\n",
        "\r\n",
        "    # return self.files[idx], torch.tensor(np.log(self.df.loc[self.gauze_ids[idx]-1, 'amount(ml)']))\r\n",
        "\r\n",
        "    #img_path = self.files[idx][0]\r\n",
        "    img_path = self.files[idx][0]\r\n",
        "    image = Image.open(img_path).convert('RGB')\r\n",
        "\r\n",
        "    if self.transform:\r\n",
        "        image = self.transform(image)\r\n",
        "\r\n",
        "    #sample = {image, np.log(self.df.loc[self.gauze_ids[idx]-1, 'amount(ml)'])}\r\n",
        "    #return image, torch.tensor(np.log(self.df.loc[self.gauze_ids[idx]-1, 'amount(ml)']))\r\n",
        "    return image, torch.tensor(self.df.loc[self.gauze_ids[idx]-1, 'amount(ml)'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIRdZz6SCcp1"
      },
      "source": [
        "#load_data(image_dir, data_type, df, gauze_ids, img_size, image_transforms[data_type])\r\n",
        "def load_data(data_dir, data, df, gauze_ids, size=128, image_transform=None):\r\n",
        "    \"\"\"\r\n",
        "    Load the train, test and validation datasets from their respective\r\n",
        "    directories\r\n",
        "    :param data_dir - a string specifying the base directory\r\n",
        "    :param data - a string specifying the type of dataset\r\n",
        "    :param df - a DataFrame containing the housing information\r\n",
        "    :param gauze_ids - a list of gauze ids\r\n",
        "    :param size - an integer specifying the size of the image\r\n",
        "    :param image_transforms - a transform object for that data type\r\n",
        "    return - a dictionary mapping the data type to the location of the image dataset\r\n",
        "    \"\"\"\r\n",
        "    return {data: GauzeDataset(df, gauze_ids, data_dir, data, size, transform=image_transform)}\r\n",
        "\r\n",
        "\r\n",
        "def transform_images(size=224):\r\n",
        "  \"\"\"\r\n",
        "  Apply transformations separately to the train, test and validation\r\n",
        "  datasets\r\n",
        "  :param size - an integer specifying the size of the image\r\n",
        "  return - a dictionary mapping the type of dataset to its transformaions\r\n",
        "  \"\"\"\r\n",
        "  data_transforms = {\r\n",
        "                    'train': transforms.Compose([\r\n",
        "                                                  # transforms.ColorJitter(\r\n",
        "                                                  #                       brightness=0.2*torch.rand(1).item(), \r\n",
        "                                                  #                       hue=0.1*torch.rand(1).item(), \r\n",
        "                                                  #                       saturation=0.3*torch.rand(1).item(),\r\n",
        "                                                  #                       contrast=0.3*torch.rand(1).item()\r\n",
        "                                                  #                       ),\r\n",
        "                                                  transforms.CenterCrop(size),\r\n",
        "                                                  transforms.ToTensor(),\r\n",
        "                                                  transforms.Normalize(\r\n",
        "                                                                   [0.485, 0.456, 0.406],\r\n",
        "                                                                   [0.229, 0.224, 0.225]\r\n",
        "                                                                      )\r\n",
        "                                                ]),\r\n",
        "                      'valid': transforms.Compose([\r\n",
        "                                                  transforms.CenterCrop(size),\r\n",
        "                                                  transforms.ToTensor(),\r\n",
        "                                                  transforms.Normalize(\r\n",
        "                                                                   [0.485, 0.456, 0.406],\r\n",
        "                                                                   [0.229, 0.224, 0.225]\r\n",
        "                                                                      )\r\n",
        "                                                 ]),\r\n",
        "                      'test': transforms.Compose([\r\n",
        "                                                  transforms.CenterCrop(size),\r\n",
        "                                                  transforms.ToTensor(),\r\n",
        "                                                  transforms.Normalize(\r\n",
        "                                                                   [0.485, 0.456, 0.406],\r\n",
        "                                                                   [0.229, 0.224, 0.225]\r\n",
        "                                                                    )\r\n",
        "                                                 ])\r\n",
        "  }\r\n",
        "  return data_transforms\r\n",
        "  \r\n",
        "def data_loader(image_datasets, data, size, shuffle=False):\r\n",
        "    \"\"\"\r\n",
        "    Create generator objects from the image datasets\r\n",
        "    :param image_datasets - an ImageFolder dataset object for that data type\r\n",
        "    :param data - a string specifying the dataset type\r\n",
        "    :param size - an integer specifying the size of the batch\r\n",
        "    :param shuffle - a bool\r\n",
        "    return a dictionary mapping the data type to the dataloader object\r\n",
        "    \"\"\"\r\n",
        "    return {data: torch.utils.data.DataLoader(image_datasets, batch_size=size, shuffle=shuffle)}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G746surjECFk"
      },
      "source": [
        "## Implement the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT5g4XofEIJu"
      },
      "source": [
        "def build_model(arch, num_classes, hidden_units=1024):\r\n",
        "  \"\"\"\r\n",
        "  Load a pretrained model with only the final layer\r\n",
        "  replaced by a user-defined classifier\r\n",
        "  :param arch - a string specifying the type of model architecture\r\n",
        "  :param num_classes - an integer specifying the number of class labels\r\n",
        "  :param hidden_units - an integer specifying the size\r\n",
        "  return - a pretrained model with a user-defined classifier\r\n",
        "  \"\"\"\r\n",
        "  in_features = 0\r\n",
        "  try:\r\n",
        "        # model = eval(\"models.\" + arch + \"(pretrained=True)\")\r\n",
        "        model = models.__dict__[arch](pretrained=True)\r\n",
        "  except:\r\n",
        "      raise Exception('Invalid architecture specified')\r\n",
        "    \r\n",
        "  # Freeze parameters as only the final layer is being trained\r\n",
        "  for param in model.parameters():\r\n",
        "      param.require_grad = False\r\n",
        "  # extract the last layer in the model\r\n",
        "  last_layer = list(model.children())[-1]\r\n",
        "  if isinstance(last_layer, nn.Sequential):\r\n",
        "      count = 0\r\n",
        "      for layer in last_layer:\r\n",
        "          if isinstance(layer, nn.Linear):\r\n",
        "              # fetch the first of the many Linear layers\r\n",
        "              count += 1\r\n",
        "              in_features = layer.in_features\r\n",
        "          if count == 1:\r\n",
        "              break\r\n",
        "  elif isinstance(last_layer, nn.Linear):\r\n",
        "      in_features = last_layer.in_features\r\n",
        "  # define the new classifier\r\n",
        "  classifier = nn.Sequential(OrderedDict([\r\n",
        "                          ('bc1', nn.BatchNorm1d(in_features)),\r\n",
        "                          ('relu1', nn.ReLU()),\r\n",
        "                          ('fc1', nn.Linear(in_features, num_classes, bias=True)),\r\n",
        "  ]))\r\n",
        "  # replace the existing classifier in thelast layer with the new one\r\n",
        "  if model.__dict__['_modules'].get('fc', None):\r\n",
        "      model.fc = classifier\r\n",
        "  else:\r\n",
        "      model.classifier = classifier\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EMe-Da-EOnF"
      },
      "source": [
        "def train_model(model, trainloader, validloader, criterion, optimizer, scheduler, epochs, diff_lr=False, device='cpu'):\r\n",
        "  \r\n",
        "  \"\"\"\r\n",
        "  Train the model and run inference on the validation dataset. Capture the loss\r\n",
        "  of the trained model and validation model. Also display the accuracy of the\r\n",
        "  validation model\r\n",
        "  :param model - a pretrain model object\r\n",
        "  :param trainloader - a generator object representing the train dataset\r\n",
        "  :param validloader - a generator object representing the validation dataset\r\n",
        "  :param criterion - a loss object\r\n",
        "  :param optimizer - an optimizer object\r\n",
        "  :param scheduler - a scheduler object that varies the learning rate every n epochs\r\n",
        "  :param epochs - an integer specifying the number of epochs to train the model\r\n",
        "  :param diff_lr - a boolean specifying whether to use differential learning rate\r\n",
        "  :param device - a string specifying whether to use cuda or cpu\r\n",
        "  return a trained model with the best weights\r\n",
        "  \"\"\"\r\n",
        "  start = time.time()\r\n",
        "  print_every = 50\r\n",
        "  steps = 0\r\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "  best_acc = 0.0\r\n",
        "  valid_loss_min = np.Inf\r\n",
        "  training_loss, validation_loss = [], []\r\n",
        "  for epoch in range(epochs):\r\n",
        "      lr_used = 0\r\n",
        "      if diff_lr:\r\n",
        "        for param in optimizer.param_groups:\r\n",
        "          if param['lr'] > lr_used:\r\n",
        "            lr_used = param['lr']\r\n",
        "        print('learning rate being used {}'.format(lr_used))      \r\n",
        "      running_loss = 0\r\n",
        "      # train_acc = 0\r\n",
        "      scheduler.step()\r\n",
        "      model.train()\r\n",
        "      for idx, (images, prices) in enumerate(trainloader):\r\n",
        "          steps += 1\r\n",
        "\r\n",
        "          images, prices = images.to(device), prices.to(device)\r\n",
        "\r\n",
        "\r\n",
        "        #added for MSE\r\n",
        "          prices = prices.to(torch.float32)\r\n",
        "\r\n",
        "          # zero the parameter gradients\r\n",
        "          optimizer.zero_grad()\r\n",
        "\r\n",
        "          # forward pass and backward pass\r\n",
        "          output = model(images)\r\n",
        "          loss = criterion(prices, output)\r\n",
        "          loss.backward()\r\n",
        "          optimizer.step()\r\n",
        "\r\n",
        "          running_loss += loss.item() * images.size(0)\r\n",
        "          # ps = torch.exp(output)\r\n",
        "          # train_acc += (ps.max(dim=1)[1] == labels.data).type(torch.FloatTensor).mean()\r\n",
        "\r\n",
        "#            if steps % print_every == 0:\r\n",
        "      # Turn off gradients for validation, saves memory and computations\r\n",
        "      with torch.no_grad():\r\n",
        "          valid_loss = validation(model, validloader, criterion, device)\r\n",
        "#           scheduler.step(test_loss)\r\n",
        "\r\n",
        "      # if test_accuracy > best_acc:\r\n",
        "      if valid_loss < valid_loss_min:\r\n",
        "          valid_loss_min = valid_loss\r\n",
        "          best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "\r\n",
        "      print(\"Epoch: {}/{}... \".format(epoch+1, epochs),\r\n",
        "        \"Train RMSLE loss: {:.4f}\".format(running_loss/len(trainloader.dataset)),\r\n",
        "        \"Validation RMSLE loss: {:.4f}\".format(valid_loss/len(validloader.dataset)),\r\n",
        "        )\r\n",
        "      # save the losses\r\n",
        "      training_loss.append(running_loss/len(trainloader.dataset))\r\n",
        "      validation_loss.append(valid_loss/len(validloader.dataset))\r\n",
        "      running_loss = 0       \r\n",
        "      \r\n",
        "  print('Best validation RMSLE loss is {:.4f}'.format(valid_loss_min/len(validloader.dataset)))\r\n",
        "  print('Time to complete training {} minutes'.format((time.time() - start) / 60))\r\n",
        "  model.load_state_dict(best_model_wts)\r\n",
        "  return model, training_loss, validation_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpPCO_amETuF"
      },
      "source": [
        "def validation(model, validloader, criterion=None, device='cpu'):\r\n",
        "    \"\"\"\r\n",
        "    Compute loss on the validation dataset\r\n",
        "    :param model - a pretrained model object\r\n",
        "    :param validloader - a generator object representing the validataion dataset\r\n",
        "    :param criterion - a loss object\r\n",
        "    :param device - a string specifying whether to use cuda or cpu\r\n",
        "    return a tuple of loss and accuracy\r\n",
        "    \"\"\"\r\n",
        "    valid_loss = 0\r\n",
        "    model.eval()\r\n",
        "    for images, prices in validloader:\r\n",
        "\r\n",
        "        images, prices = images.to(device), prices.to(device)\r\n",
        "        output = model(images)\r\n",
        "        valid_loss += criterion(prices, output).item() * images.size(0)\r\n",
        "    \r\n",
        "    return valid_loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnVbXqZdEcvn"
      },
      "source": [
        "class RMSLELoss(nn.Module):\r\n",
        "    r\"\"\"Creates a criterion that measures the root mean square error (MAE) between each element in\r\n",
        "    the input :math:`x` and target :math:`y`.\r\n",
        "    Examples::\r\n",
        "        >>> loss = nn.RMSLELoss()\r\n",
        "        >>> input = torch.randn(3, 5, requires_grad=True)\r\n",
        "        >>> target = torch.randn(3, 5)\r\n",
        "        >>> output = loss(input, target)\r\n",
        "        >>> output.backward()\r\n",
        "    \"\"\"\r\n",
        "    __constants__ = ['reduction']\r\n",
        "\r\n",
        "    def __init__(self, size_average=None, reduce=None, reduction='mean'):\r\n",
        "        super(RMSLELoss, self).__init__()\r\n",
        "\r\n",
        "    def forward(self, input, target):\r\n",
        "      return rmsle(input, target)\r\n",
        "\r\n",
        "def rmsle(actual_prices, predicted_prices):\r\n",
        "    \"\"\"\r\n",
        "    Compute Root Mean Square Log Error\r\n",
        "    :param actual_prices - a Tensor vector of log transformed house prices\r\n",
        "    :param predicted_prices - a Tensor vector of predicted house prices\r\n",
        "    return - Mean Absolute Percentage Error\r\n",
        "    \"\"\"\r\n",
        "    return torch.sqrt(torch.mean((actual_prices - predicted_prices) ** 2))\r\n",
        "    \r\n",
        "\r\n",
        "class LogCoshLoss(torch.nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "    def forward(self, actual_prices, predicted_prices):\r\n",
        "        ey_t = predicted_prices - actual_prices\r\n",
        "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\r\n",
        "\r\n",
        "# class HuberLoss(nn.Module):\r\n",
        "#     r\"\"\"Creates a criterion that measures the huber between each element in\r\n",
        "#     the input :math:`x` and target :math:`y`.\r\n",
        "#     Examples::\r\n",
        "#         >>> loss = nn.RMSLELoss()\r\n",
        "#         >>> input = torch.randn(3, 5, requires_grad=True)\r\n",
        "#         >>> target = torch.randn(3, 5)\r\n",
        "#         >>> output = loss(input, target)\r\n",
        "#         >>> output.backward()\r\n",
        "#     \"\"\"\r\n",
        "#     __constants__ = ['reduction']\r\n",
        "\r\n",
        "#     def __init__(self, size_average=None, reduce=None, reduction='mean', delta=0.1):\r\n",
        "#         super(HuberLoss, self).__init__()\r\n",
        "#         self.delta = delta\r\n",
        "\r\n",
        "#     def forward(self, input, target):\r\n",
        "#       return huber(input, target, self.delta)\r\n",
        "\r\n",
        "# def huber(actual_prices, predicted_prices, delta):\r\n",
        "#     loss = np.where(np.abs(actual_prices-predicted_prices) < delta , 0.5*((actual_prices-predicted_prices)**2), delta*np.abs(actual_prices - predicted_prices) - 0.5*(delta**2))\r\n",
        "#     return torch.sum(loss)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def optimizer(model, lr=0.001, weight_decay=1e-3/200):\r\n",
        "    \"\"\"\r\n",
        "    Define the optimizer used to reduce the loss\r\n",
        "    :param model - a pretrained model object\r\n",
        "    :param lr - a floating point value defining the learning rate\r\n",
        "    :param weight_decay - apply L2 regularization\r\n",
        "    return an optimizer object\r\n",
        "    \"\"\"\r\n",
        "    if model.__dict__['_modules'].get('fc', None):\r\n",
        "        return optim.Adam(model.fc.parameters(), lr=lr, weight_decay=weight_decay)\r\n",
        "    return optim.Adam(model.classifier.parameters(), lr=lr, weight_decay=weight_decay)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7z211bhEiFm"
      },
      "source": [
        "def check_rmsle_on_test(model, testloader, criterion=None, device='cpu', scale_factor=1e6):  \r\n",
        "    \"\"\"\r\n",
        "    Compute the Root Mean Square Error on the test dataset\r\n",
        "    :param model - a pretrained model object\r\n",
        "    :param testloader - a generator object representing the test dataset\r\n",
        "    :param criterion - loss object\r\n",
        "    :param device - a string specifying whether to use cuda or cpu\r\n",
        "    :param scale_factor - a float to scale the house prices\r\n",
        "    return - RMSLE of predicted house prices\r\n",
        "    \"\"\"\r\n",
        "    loss = 0\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for data in testloader:\r\n",
        "            images, prices = data\r\n",
        "            images, prices = images.to(device), prices.to(device)\r\n",
        "            outputs = model(images)\r\n",
        "            loss += criterion(prices, outputs)\r\n",
        " #           mae += 100 * torch.abs((prices - outputs) / prices)\r\n",
        " #           mae += mape(prices, outputs)\r\n",
        "        loss = np.squeeze(loss.numpy()) if device == 'cpu' else np.squeeze(loss.cpu().numpy())\r\n",
        "\r\n",
        "    return loss / len(testloader)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVh9br1rc3Vs"
      },
      "source": [
        "def predict_prices(model, testloader, criterion=None, device='cpu', scale_factor=1e6):  \r\n",
        "    \"\"\"\r\n",
        "    Compute the Root Mean Square Error on the test dataset\r\n",
        "    :param model - a pretrained model object\r\n",
        "    :param testloader - a generator object representing the test dataset\r\n",
        "    :param criterion - loss object\r\n",
        "    :param device - a string specifying whether to use cuda or cpu\r\n",
        "    :param scale_factor - a float to scale the house prices\r\n",
        "    return - RMSLE of predicted house prices\r\n",
        "    \"\"\"\r\n",
        "    outputs = []\r\n",
        "    pricess = []\r\n",
        "    loss = 0\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for data in testloader:\r\n",
        "            images, prices = data\r\n",
        "            images, prices = images.to(device), prices.to(device)\r\n",
        "            output = model(images)\r\n",
        "            outputs.append(output)\r\n",
        "            pricess.append(prices)\r\n",
        "            #output = model(images)            \r\n",
        "            #loss += criterion(prices, outputs)\r\n",
        " #           mae += 100 * torch.abs((prices - outputs) / prices)\r\n",
        " #           mae += mape(prices, outputs)\r\n",
        "        #loss = np.squeeze(loss.numpy()) if device == 'cpu' else np.squeeze(loss.cpu().numpy())\r\n",
        "\r\n",
        "\r\n",
        "    return outputs, pricess"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv4rYSzk_FN0"
      },
      "source": [
        "def plot_losses(training_loss, validation_loss, epochs, split):\r\n",
        "\r\n",
        "  os.makedirs(\"plots\", exist_ok = True)\r\n",
        "  plt.figure()\r\n",
        "  plt.plot(training_loss, label='training loss')\r\n",
        "  plt.plot(validation_loss, label='validation loss')\r\n",
        "  plt.legend(frameon=False)\r\n",
        "  plt.xlabel('epoch')\r\n",
        "  plt.ylabel('loss')\r\n",
        "  plt.title('Loss vs. No. of epochs')  \r\n",
        "  plt.savefig(\"plots/logcosh_losses_resnet_\"+split+\".png\")\r\n",
        "  plt.show()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqtO3QStGzM_"
      },
      "source": [
        "##Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SING1IfrAgy-",
        "outputId": "1b0452a2-bf0a-4274-a0d3-89c752504aca"
      },
      "source": [
        "device = \"cpu\"\r\n",
        "gpu = True\r\n",
        "if gpu:\r\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "  print('Use device:', device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfWEauxd1S9t"
      },
      "source": [
        "def train(dataloader, split, epochs, criterion):\r\n",
        "  arch = 'resnet50'\r\n",
        "  hidden_units = 64\r\n",
        "  lr = 0.0001\r\n",
        "  #epochs = 50\r\n",
        "  \r\n",
        "  num_classes = 1 # for regression\r\n",
        "\r\n",
        "  model = build_model(arch, num_classes, hidden_units)\r\n",
        "\r\n",
        "  optim_ = optimizer(model, lr)\r\n",
        "  #exp_lr_scheduler = lr_scheduler.StepLR(optim_, step_size=5, gamma=0.1)\r\n",
        "  exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optim_, T_max=epochs)\r\n",
        "  # default\r\n",
        "  # device = \"cpu\"\r\n",
        "  # if gpu:\r\n",
        "  #     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "  # print('Use device:', device)\r\n",
        "  model = model.to(device) \r\n",
        "  print('Training begins...')\r\n",
        "  model, training_loss, validation_loss = train_model(model, dataloader['train'], \r\n",
        "                                                      dataloader['valid'], criterion, \r\n",
        "                      optim_, exp_lr_scheduler, epochs, False, device) \r\n",
        "  \r\n",
        "\r\n",
        "  plot_losses(training_loss, validation_loss, epochs, split)\r\n",
        "\r\n",
        "  return model\r\n",
        "\r\n",
        "#model = train(dataloader)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-SGYEPm1X_Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvOCNClK1oXq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k04K0a7G1qSs"
      },
      "source": [
        "def save_outputs(outputs, prices, split):\r\n",
        "  outputs = torch.FloatTensor(outputs)\r\n",
        "  outputs = outputs.numpy()\r\n",
        "  print(outputs)\r\n",
        "\r\n",
        "  prices = torch.FloatTensor(prices)\r\n",
        "  prices = prices.numpy()\r\n",
        "  print(prices)\r\n",
        "\r\n",
        "  os.makedirs(\"model_result\", exist_ok=True)\r\n",
        "\r\n",
        "  df_outputs = pd.DataFrame(outputs)\r\n",
        "  df_outputs.to_csv('model_result/logcosh_predicted_'+split+'.csv', index=False)\r\n",
        "  df_prices =  pd.DataFrame(prices)\r\n",
        "  df_prices.to_csv('model_result/logcosh_truevalue_try'+split+'.csv', index=False)\r\n",
        "\r\n",
        "\r\n",
        "# os.makedirs(\"plots\", exist_ok = True)\r\n",
        "\r\n",
        "# plt.figure()\r\n",
        "# plt.plot(outputs, label='prediction')\r\n",
        "# plt.plot(a, label='true value')\r\n",
        "# plt.legend(frameon=False)\r\n",
        "# #plt.xlabel('epoch')\r\n",
        "# plt.ylabel('value')\r\n",
        "# plt.title('Loss vs. No. of epochs')  \r\n",
        "# plt.savefig(\"plots/values_comparison_2.png\")\r\n",
        "# plt.show()\r\n",
        "\r\n",
        "# pb = b.numpy()\r\n",
        "# px = pd.DataFrame(px)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR8kC5d81i2p"
      },
      "source": [
        "def plot_predicted_true_value(outputs, prices, split):\r\n",
        "  # data to plot\r\n",
        "  n_groups = len(outputs)\r\n",
        "\r\n",
        "  # create plot\r\n",
        "  fig, ax = plt.subplots()\r\n",
        "  index = np.arange(n_groups)\r\n",
        "  bar_width = 0.35\r\n",
        "  opacity = 0.8\r\n",
        "\r\n",
        "  rects1 = plt.bar(index, outputs, bar_width,\r\n",
        "  alpha=opacity,\r\n",
        "  color='b',\r\n",
        "  label='predicted')\r\n",
        "\r\n",
        "  rects2 = plt.bar(index + bar_width, prices, bar_width,\r\n",
        "  alpha=opacity,\r\n",
        "  color='g',\r\n",
        "  label='true value')\r\n",
        "\r\n",
        "  plt.xlabel('Type')\r\n",
        "  plt.ylabel('Value')\r\n",
        "  plt.title('Predicted vs True Value')\r\n",
        "  #plt.xticks(index + bar_width, ('A', 'B', 'C', 'D', 'E'))\r\n",
        "  plt.legend()\r\n",
        "\r\n",
        "  plt.tight_layout()\r\n",
        "\r\n",
        "  plt.savefig(\"plots/logcosh_value_\"+split+\".png\")\r\n",
        "  plt.show()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lMNVen837cY",
        "outputId": "f563e02d-7d90-4a00-e0a0-02231146d69e"
      },
      "source": [
        "def load_dataset():\r\n",
        "  image_dir = r'renamed_labeled_dataset'\r\n",
        "  train_ids, test_ids, valid_ids = split_into_train_test_valid(image_dir)\r\n",
        "  \r\n",
        "  for i in range(len(train_ids)):\r\n",
        "    print(\"Split\" + str(i))\r\n",
        "    make_dirs_copy_images(image_dir, \"split\"+str(i), train_ids[i], test_ids[i], valid_ids[i])\r\n",
        "    df = parse_gauze_info(image_dir, 'labels_4x4.csv')\r\n",
        "\r\n",
        "    train_batch_size= 32\r\n",
        "    test_batch_size = 1\r\n",
        "    valid_batch_size = 32\r\n",
        "    img_size = 128\r\n",
        "    transform_img_size = 224\r\n",
        "\r\n",
        "    #criterion = torch.nn.MSELoss()\r\n",
        "    #criterion = RMSLELoss()\r\n",
        "    #criterion = torch.nn.L1Loss()\r\n",
        "    #criterion = torch.nn.SmoothL1Loss()\r\n",
        "    criterion = LogCoshLoss()\r\n",
        "\r\n",
        "    image_datasets = {}\r\n",
        "    dataloader = {}\r\n",
        "    image_transforms = transform_images(size=transform_img_size)\r\n",
        "    try:\r\n",
        "      for data_type, gauze_ids, batch_size, shuffle in zip(['train', 'test', 'valid'],\r\n",
        "                          [train_ids[i], test_ids[i], valid_ids[i]],\r\n",
        "                          [train_batch_size, test_batch_size, valid_batch_size],\r\n",
        "                          [True, False, True]):\r\n",
        "        image_datasets.update(load_data(image_dir+\"/\"+\"split\"+str(i), data_type, df, gauze_ids, img_size, image_transforms[data_type]))\r\n",
        "        dataloader.update(data_loader(image_datasets[data_type], data_type, batch_size, shuffle))\r\n",
        "    except:  \r\n",
        "        raise Exception('Loading of dataset failed...')\r\n",
        "\r\n",
        "    model = train(dataloader, \"split\"+str(i), 30, criterion)\r\n",
        "\r\n",
        "    test_loss = check_rmsle_on_test(model, dataloader['test'], criterion, device)\r\n",
        "    print('Test set RMSLE loss is {:.4f}'.format(test_loss))\r\n",
        "\r\n",
        "    outputs, prices = predict_prices(model, dataloader['test'], criterion,\r\n",
        "                  device='cuda', scale_factor=1)\r\n",
        "    \r\n",
        "    save_outputs(outputs, prices, \"split\"+str(i))\r\n",
        "    plot_predicted_true_value(outputs, prices, \"split\"+str(i))\r\n",
        "\r\n",
        "    \r\n",
        "load_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split0\n",
            "Training begins...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/30...  Train RMSLE loss: 3.8893 Validation RMSLE loss: 3.6330\n",
            "Epoch: 2/30...  Train RMSLE loss: 3.6498 Validation RMSLE loss: 3.4307\n",
            "Epoch: 3/30...  Train RMSLE loss: 3.4295 Validation RMSLE loss: 3.2393\n",
            "Epoch: 4/30...  Train RMSLE loss: 3.2124 Validation RMSLE loss: 3.0830\n",
            "Epoch: 5/30...  Train RMSLE loss: 3.0044 Validation RMSLE loss: 2.9685\n",
            "Epoch: 6/30...  Train RMSLE loss: 2.8128 Validation RMSLE loss: 2.8093\n",
            "Epoch: 7/30...  Train RMSLE loss: 2.6565 Validation RMSLE loss: 2.6873\n",
            "Epoch: 8/30...  Train RMSLE loss: 2.5158 Validation RMSLE loss: 2.5548\n",
            "Epoch: 9/30...  Train RMSLE loss: 2.3738 Validation RMSLE loss: 2.4084\n",
            "Epoch: 10/30...  Train RMSLE loss: 2.2709 Validation RMSLE loss: 2.2601\n",
            "Epoch: 11/30...  Train RMSLE loss: 2.1817 Validation RMSLE loss: 2.1363\n",
            "Epoch: 12/30...  Train RMSLE loss: 2.0792 Validation RMSLE loss: 2.0341\n",
            "Epoch: 13/30...  Train RMSLE loss: 2.0114 Validation RMSLE loss: 1.9613\n",
            "Epoch: 14/30...  Train RMSLE loss: 1.9852 Validation RMSLE loss: 1.9090\n",
            "Epoch: 15/30...  Train RMSLE loss: 1.9181 Validation RMSLE loss: 1.8855\n",
            "Epoch: 16/30...  Train RMSLE loss: 1.9070 Validation RMSLE loss: 1.8572\n",
            "Epoch: 17/30...  Train RMSLE loss: 1.8478 Validation RMSLE loss: 1.8586\n",
            "Epoch: 18/30...  Train RMSLE loss: 1.8267 Validation RMSLE loss: 1.8443\n",
            "Epoch: 19/30...  Train RMSLE loss: 1.8161 Validation RMSLE loss: 1.7965\n",
            "Epoch: 20/30...  Train RMSLE loss: 1.7904 Validation RMSLE loss: 1.7913\n",
            "Epoch: 21/30...  Train RMSLE loss: 1.7815 Validation RMSLE loss: 1.7547\n",
            "Epoch: 22/30...  Train RMSLE loss: 1.7888 Validation RMSLE loss: 1.7753\n",
            "Epoch: 23/30...  Train RMSLE loss: 1.7657 Validation RMSLE loss: 1.7757\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}